"use strict";(globalThis.webpackChunkrubenlinde_website=globalThis.webpackChunkrubenlinde_website||[]).push([[4328],{2957(e){e.exports=JSON.parse('{"permalink":"/blog/ai-risicos-niet-adopteren-achterblijven","source":"@site/blog/platform-ai-en-overheid/2025-01-21-ai-risicos-niet-adopteren.md","title":"Risico\'s van Niet-Adopteren - Als de overheid AI negeert","description":"Deze blog is geschreven in het kader van Platform AI en Overheid, een initiatief gericht op verantwoorde AI-adoptie binnen de publieke sector.","date":"2025-01-21T00:00:00.000Z","tags":[{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"overheid","permalink":"/blog/tags/overheid"}],"readingTime":4.72,"hasTruncateMarker":true,"authors":[{"name":"Ruben van der Linde","title":"Software Developer","url":"https://github.com/rubenvdlinde","email":"your-email@example.com","imageURL":"https://github.com/rubenvdlinde.png","key":"ruben","page":null}],"frontMatter":{"slug":"ai-risicos-niet-adopteren-achterblijven","title":"Risico\'s van Niet-Adopteren - Als de overheid AI negeert","authors":["ruben"],"tags":["ai","overheid"]},"unlisted":false,"prevItem":{"title":"Het Einde van Pax Americana - Tijd voor digitale soevereiniteit","permalink":"/blog/einde-pax-americana-digitale-soevereiniteit"},"nextItem":{"title":"AI en Burgers: Kansen voor een betere dienstverlening","permalink":"/blog/ai-kansen-burgers-regelgeving-navigator"}}')},5299(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>v,frontMatter:()=>o,metadata:()=>t,toc:()=>d});var t=i(2957),r=i(4848),a=i(8453);const o={slug:"ai-risicos-niet-adopteren-achterblijven",title:"Risico's van Niet-Adopteren - Als de overheid AI negeert",authors:["ruben"],tags:["ai","overheid"]},s="Risico's van Niet-Adopteren: Als de overheid AI negeert",l={authorsImageUrls:[void 0]},d=[];function c(e){const n={a:"a",admonition:"admonition",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.admonition,{title:"Platform AI en Overheid",type:"info",children:(0,r.jsxs)(n.p,{children:["Deze blog is geschreven in het kader van ",(0,r.jsx)(n.a,{href:"https://www.platformaienoverheid.nl/",children:"Platform AI en Overheid"}),", een initiatief gericht op verantwoorde AI-adoptie binnen de publieke sector."]})}),"\n",(0,r.jsxs)(n.p,{children:["We praten veel over de risico's van AI \u2013 bias, privacy, banenverlies, black boxes. Terecht, want die gevaren zijn re\xebel en moeten we serieus nemen.[^2][^8] Maar er is een ander risico dat vaak onderbelicht blijft, en dat misschien wel groter is: het risico van ",(0,r.jsx)(n.strong,{children:"niet adopteren"}),". Terwijl we eindeloos discussi\xebren, pilots uitstellen en wachten op perfectie, gaat de wereld om ons heen vol gas vooruit. Bedrijven, burgers en andere landen omarmen AI \u2013 en de overheid blijft achter.[^1][^2] Dat is geen neutrale positie; dat is een keuze met verstrekkende gevolgen.[^7]"]}),"\n",(0,r.jsx)(n.p,{children:"Stel je voor: over een paar jaar hebben burgers persoonlijke AI-assistenten die alles regelen \u2013 van belastingen tot zorgaanvragen. Ze verwachten dat de overheid net zo snel, slim en persoonlijk is. Maar als we nu niet investeren, wordt de kloof onoverbrugbaar.[^1][^5] Achterblijven is niet stilstand; het is achteruitgang. Laten we kijken naar de risico's van niet meedoen \u2013 want die zijn minstens zo groot als de risico's van wel doen.[^2]"})]})}function v(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const r={},a=t.createContext(r);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);