"use strict";(globalThis.webpackChunkrubenlinde_website=globalThis.webpackChunkrubenlinde_website||[]).push([[8823],{6483(e,n,i){i.r(n),i.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>g,frontMatter:()=>o,metadata:()=>a,toc:()=>d});var a=i(9411),t=i(4848),r=i(8453);const o={slug:"ai-techniek-integratie-mcp-mistral",title:"AI en Techniek - Veilige integratie en het Mistral-vraagstuk",authors:["ruben"],tags:["ai","techniek","mcp","mistral","platform-ai","overheid","modellen"]},l="AI en Techniek: Veilige integratie",s={authorsImageUrls:[void 0]},d=[{value:"Hoe AI Werkt: Reasoning in Leken Taal",id:"hoe-ai-werkt-reasoning-in-leken-taal",level:2},{value:"De Brug naar de Datalaag: Data Ophalen en Vectorisatie",id:"de-brug-naar-de-datalaag-data-ophalen-en-vectorisatie",level:2},{value:"Hallucineren: Wat Het Is, Waarom Het Gebeurt, Hoe Te Mitigeren",id:"hallucineren-wat-het-is-waarom-het-gebeurt-hoe-te-mitigeren",level:2},{value:"Waarschijnlijkheid vs Zekerheid: AI&#39;s Onvoorspelbaarheid tegenover DMN&#39;s Rigiditeit",id:"waarschijnlijkheid-vs-zekerheid-ais-onvoorspelbaarheid-tegenover-dmns-rigiditeit",level:2},{value:"AI Integreren met Bestaande Applicaties: MCP als Sleutel",id:"ai-integreren-met-bestaande-applicaties-mcp-als-sleutel",level:2},{value:"Workflow Engines: Snel Business Logica Uitvoeren met n8n",id:"workflow-engines-snel-business-logica-uitvoeren-met-n8n",level:2},{value:"DMN Engines voor Complexe Processen: De Open Source Opvolger van Camunda",id:"dmn-engines-voor-complexe-processen-de-open-source-opvolger-van-camunda",level:2},{value:"Het Punt: AI Niet voor Procesafhandeling, Wel voor Logica en Advies",id:"het-punt-ai-niet-voor-procesafhandeling-wel-voor-logica-en-advies",level:2},{value:"Juridische Duiding: Het Handelingskader van AI",id:"juridische-duiding-het-handelingskader-van-ai",level:2},{value:"Handelen Namens Medewerkers: OAuth met Tokens in RBAC/PBAC",id:"handelen-namens-medewerkers-oauth-met-tokens-in-rbacpbac",level:2},{value:"Beveiliging en Isolatie: AI in de &#39;Kelder&#39; Houden",id:"beveiliging-en-isolatie-ai-in-de-kelder-houden",level:2},{value:"AI als Ondersteunende Tool: Samenvatten, Genereren, Structureren \u2013 Met Menselijke Controle",id:"ai-als-ondersteunende-tool-samenvatten-genereren-structureren--met-menselijke-controle",level:2},{value:"Kritische Vraag: Blijft AI Altijd Ondersteunend?",id:"kritische-vraag-blijft-ai-altijd-ondersteunend",level:2},{value:"Conclusie",id:"conclusie",level:2},{value:"Bronnen",id:"bronnen",level:2}];function c(e){const n={a:"a",admonition:"admonition",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.admonition,{title:"Status: Concept",type:"warning",children:(0,t.jsx)(n.p,{children:"Deze blog is nog in concept-fase en wordt mogelijk nog aangepast voor publicatie."})}),"\n",(0,t.jsx)(n.p,{children:"AI-integratie in overheidsapplicaties brengt unieke uitdagingen met zich mee \u2013 hoe zorg je dat AI veilig toegang krijgt tot data, zonder risico's op lekken of foute adviezen? Dit blog legt in leken taal uit hoe AI werkt met reasoning, hoe data veilig opgehaald wordt met vectorisatie, en hoe tools als MCP context bieden. We verkennen workflow engines voor business logica, met focus op waarom AI niet voor uitvoering is (te onvoorspelbaar), maar wel voor setup en advies. Juridische kaders en authenticatie met OAuth in RBAC/PBAC komen aan bod, plus beveiliging met on-premise deployment. Doel: verantwoord integreren, passend bij publieke waarden."}),"\n",(0,t.jsx)(n.h2,{id:"hoe-ai-werkt-reasoning-in-leken-taal",children:"Hoe AI Werkt: Reasoning in Leken Taal"}),"\n",(0,t.jsx)(n.p,{children:'Laten we beginnen bij de basis: hoe "werkt" AI eigenlijk? In eenvoudige termen is AI als een superslimme assistent die patronen herkent en voorspellingen doet op basis van data. Maar het echte "denken" gebeurt via reasoning \u2013 een stap-voor-stap proces dat lijkt op hoe een mens redeneert, maar dan razendsnel en met enorme hoeveelheden info. Stel, je vraagt een AI om een subsidie te beoordelen. Het breekt de vraag op: eerst begrijpt het de input (jouw situatie), dan "redeneert" het door mogelijke regels te chainen (stap 1: check leeftijd, stap 2: inkomen, stap 3: regio). Dit heet "chain of thought" reasoning \u2013 de AI bouwt een ketting van gedachten, vaak met threading (meerdere parallelle denkpaden om opties te verkennen). Door deze parallelle gedachten en het samenvatten van uitkomsten, denkt AI eigenlijk als een team in plaats van als persoon \u2013 verschillende "idee\xebn" worden bekeken en gecombineerd tot een coherent antwoord.'}),"\n",(0,t.jsx)(n.p,{children:'Neem een anekdote: een gemeente-ambtenaar gebruikt AI voor een toeslagvraag. De AI "redeneert": "Burger is 35, alleenstaand, inkomen onder drempel \u2013 check regel X uit wet Y." Het resultaat? Snelle, traceerbare adviezen. Maar zonder goede data is dit nutteloos \u2013 wat ons brengt bij de brug naar de datalaag.'}),"\n",(0,t.jsx)(n.h2,{id:"de-brug-naar-de-datalaag-data-ophalen-en-vectorisatie",children:"De Brug naar de Datalaag: Data Ophalen en Vectorisatie"}),"\n",(0,t.jsx)(n.p,{children:'AI is niks zonder data \u2013 het is als een auto zonder benzine. In overheidscontext haal je data op uit bronnen zoals Common Ground-registers (BRP voor persoonsgegevens, BAG voor adressen). Dit gebeurt via API\'s: korte, veilige queries die alleen nodige info ophalen \u2013 geen hele database, maar "short range" opvragingen voor snelheid en privacy.'}),"\n",(0,t.jsx)(n.p,{children:'Om AI slim te maken, gebruik je vectorisatie: data omzetten in wiskundige vectors (getallenreeksen) die patronen makkelijk herkennen. Concreet: een vector representatie van tekst is een lijst getallen die de betekenis vastlegt \u2013 "kat" wordt bijv. [0.2, 0.8, -0.1, ...], "poes" iets vergelijkbaars. Waarom beter dan woordvergelijking? Bij woorden match je exact ("kat" \u2260 "poes"), bij vectors meet je afstand \u2013 semantically similar teksten liggen dichtbij, dus vind je "kat" bij zoektocht naar "huisdier", zelfs zonder exacte woorden. Dit geeft betere, contextuele resultaten. Voor details over de datalaag, zie ons blog "AI en Data: Waarom de datalaag alles bepaalt". Hier focussen we op integratie: haal data veilig op, vectoriseer voor AI-redenering, en koppel terug aan applicaties.'}),"\n",(0,t.jsx)(n.h2,{id:"hallucineren-wat-het-is-waarom-het-gebeurt-hoe-te-mitigeren",children:"Hallucineren: Wat Het Is, Waarom Het Gebeurt, Hoe Te Mitigeren"}),"\n",(0,t.jsx)(n.p,{children:'Een veelvoorkomend probleem bij AI is hallucineren \u2013 de AI "verzint" feiten die niet kloppen. Wat is het precies? Hallucineren gebeurt wanneer AI plausibele maar onjuiste informatie genereert, omdat het probabilistisch werkt: het voorspelt volgende woorden op basis van patronen in trainingsdata, niet op feiten. Waarom? Door gaps in data, ambigu\xefteit in queries, of overgeneraliserende modellen. Voorbeeld: vraag "wie won WK 2026?", AI "hallucineert" een winnaar als data stoppen bij 2025.'}),"\n",(0,t.jsx)(n.p,{children:"Hoe mitigeren? Gebruik RAG (Retrieval-Augmented Generation): haal actuele data op en voed het aan AI, zodat het baseert op feiten. Of chain of thought: dwing stap-voor-stap redenering. In overheid: koppel aan betrouwbare bronnen als regels.overheid.nl \u2013 minder risico's op foute adviezen."}),"\n",(0,t.jsx)(n.h2,{id:"waarschijnlijkheid-vs-zekerheid-ais-onvoorspelbaarheid-tegenover-dmns-rigiditeit",children:"Waarschijnlijkheid vs Zekerheid: AI's Onvoorspelbaarheid tegenover DMN's Rigiditeit"}),"\n",(0,t.jsx)(n.p,{children:"AI is probabilistisch: het berekent waarschijnlijkheden, dus nooit exact dezelfde uitkomst \u2013 kleine variaties in input of model leiden tot verschillen, ideaal voor creatieve taken maar riskant voor consistentie. DMN-engines daarentegen zijn deterministisch: altijd dezelfde uitkomst bij dezelfde input, rigid op kaders \u2013 perfect voor regelgeving waar zekerheid cruciaal is, maar minder flexibel voor nuances."}),"\n",(0,t.jsx)(n.p,{children:"In overheid: gebruik AI voor exploratie (advies), DMN voor uitvoering (besluiten) \u2013 balans tussen innovatie en betrouwbaarheid."}),"\n",(0,t.jsx)(n.h2,{id:"ai-integreren-met-bestaande-applicaties-mcp-als-sleutel",children:"AI Integreren met Bestaande Applicaties: MCP als Sleutel"}),"\n",(0,t.jsx)(n.p,{children:"Nu de integratie: hoe koppel je AI aan bestaande overheidsapps zonder chaos? Hier komt het Model Context Protocol (MCP) om de hoek \u2013 een standaard die AI veilig context geeft. MCP is als een portier: het laat AI alleen zien wat nodig is, via gecontroleerde API's. Verschil met gewone API? API's halen data op, MCP voegt context toe \u2013 \"niet alleen data, maar waarom en hoe het gebruikt mag worden\". Bijvoorbeeld: AI krijgt via MCP alleen geanonimiseerde info voor een advies, geen volledige dossiers."}),"\n",(0,t.jsx)(n.p,{children:"MCP werkt met drie principes: alleen noodzakelijke context (geen hele database, maar specifieke datapunten via API's), geen vrije toegang (AI roept niet zelf systemen aan, applicatie controleert), API-gedreven (input valideren, output checken, acties loggen). Dit voorkomt misbruik, houdt alles traceerbaar. De standaard, ontwikkeld door Anthropic, is open en evolueert \u2013 zie hun documentatie voor details."}),"\n",(0,t.jsx)(n.p,{children:'In praktijk: MCP maakt AI "context-aware" \u2013 veilig, effici\xebnt, compliant met AVG en AI Act.'}),"\n",(0,t.jsx)(n.h2,{id:"workflow-engines-snel-business-logica-uitvoeren-met-n8n",children:"Workflow Engines: Snel Business Logica Uitvoeren met n8n"}),"\n",(0,t.jsx)(n.p,{children:'AI schittert in workflow engines \u2013 tools die processen automatiseren. Neem n8n, een open source engine voor snelle business logica. Hier kun je met een AI-agent, via n8n\'s MCP, conversatief een business logica proces opzetten: praat met de agent ("Maak een flow voor subsidiechecks: check inkomen, dan leeftijd, dan advies"), agent bouwt nodes (stapjes) \u2013 AI-node voor check, notificatie-node. Eenmaal opgezet, draait het zelfstandig, elke keer exact hetzelfde, zonder verdere AI-input \u2013 deterministic en betrouwbaar.'}),"\n",(0,t.jsx)(n.p,{children:"n8n voert logica uit als een orkestdirigent \u2013 effici\xebnt, schaalbaar."}),"\n",(0,t.jsx)(n.h2,{id:"dmn-engines-voor-complexe-processen-de-open-source-opvolger-van-camunda",children:"DMN Engines voor Complexe Processen: De Open Source Opvolger van Camunda"}),"\n",(0,t.jsx)(n.p,{children:'Voor complexe processen, zoals zaakafhandeling met beoordelingskaders en menselijk oordeel, kies een DMN-engine (Decision Model and Notation). De open source opvolger van Camunda, zoals Flowable, is perfect hiervoor. Deze engines modeleren besluiten als tabellen \u2013 "als inkomen < X en leeftijd > Y, dan subsidie Z" \u2013 geschikt voor overheidszaken waar wetten, regels en menselijk ingrijpen centraal staan.'}),"\n",(0,t.jsx)(n.p,{children:"Voorbeeld: vergunningaanvraag \u2013 DMN-engine evalueert kader, AI adviseert, mens beslist. Menselijk handelen blijft cruciaal \u2013 AI ondersteunt, engine structureert."}),"\n",(0,t.jsx)(n.h2,{id:"het-punt-ai-niet-voor-procesafhandeling-wel-voor-logica-en-advies",children:"Het Punt: AI Niet voor Procesafhandeling, Wel voor Logica en Advies"}),"\n",(0,t.jsx)(n.p,{children:"Belangrijk punt: gebruik AI niet voor volledige procesafhandeling \u2013 te onvoorspelbaar, risico op biases of fouten in kritieke stappen. Wel voor inrichten business logica, processen en rekenregels \u2013 AI niet in de uitvoeirng gebruikgt voor de logica maar vooraf als tool om de logica mee klaar te zetten, die logica word vervolgens door een mens gecontroleerd en daarna automatisch uitgeveord. Verbinding met regels.overheid.nl: AI haalt machine-leesbare regels op, vertaalt naar DMN-tabellen \u2013 automatisering van rekenregels zonder mens te vervangen."}),"\n",(0,t.jsx)(n.p,{children:'Binnen processen: AI brengt advies uit aan medewerkers, verzamelt relevante regels/wetten, koppelt aan dossier \u2013 "Op basis van wet X adviseer ik Y, maar check Z." Maar blijft binnen handelingskader: geen inhoudelijke besluiten, die zijn juridisch menselijk \u2013 AI adviseert, mens beslist en is verantwoordelijk (Awb, AI Act).'}),"\n",(0,t.jsx)(n.h2,{id:"juridische-duiding-het-handelingskader-van-ai",children:"Juridische Duiding: Het Handelingskader van AI"}),"\n",(0,t.jsx)(n.p,{children:"Juridisch gezien mag AI in overheid geen handelingsbevoegdheid hebben \u2013 besluiten moeten herleidbaar zijn tot een menselijke ambtenaar (Awb). AI is tool, geen actor; het mag adviseren of voorbereiden, maar nooit bindende beslissingen nemen, rechten toekennen/ontzeggen of plichten opleggen. Dit voorkomt aansprakelijkheidskwesties en waarborgt democratie \u2013 mens blijft accountable. In EU AI Act high-risk categorie\xebn vereist dit expliciete menselijke oversight."}),"\n",(0,t.jsx)(n.h2,{id:"handelen-namens-medewerkers-oauth-met-tokens-in-rbacpbac",children:"Handelen Namens Medewerkers: OAuth met Tokens in RBAC/PBAC"}),"\n",(0,t.jsx)(n.p,{children:'Om AI veilig namens medewerkers te laten handelen, gebruik OAuth met tokens binnen RBAC (Role-Based Access Control) of PBAC (Policy-Based Access Control). RBAC geeft toegang op rol (bijv. "ambtenaar" mag lezen), PBAC op policies (bijv. "toegang als toestemming en context kloppen"). OAuth genereert tokens \u2013 tijdelijke sleutels waarmee AI namens user data ophaalt, maar binnen grenzen (geen wijzigingen). Voorbeeld: ambtenaar logt in, token aan AI, AI queryt via API \u2013 gelogd, revokeerbaar. Dit houdt controle, voorkomt misbruik.'}),"\n",(0,t.jsx)(n.h2,{id:"beveiliging-en-isolatie-ai-in-de-kelder-houden",children:"Beveiliging en Isolatie: AI in de 'Kelder' Houden"}),"\n",(0,t.jsx)(n.p,{children:'Beveiliging draait om isolatie. AI draait "in de kelder" \u2013 on-premise: geen data naar externe clouds, volledige controle over infrastructuur, compliance met privacy. Metafoor: AI en data in hetzelfde "kasteel" \u2013 veilig binnen muren, niet in big tech-clouds.'}),"\n",(0,t.jsx)(n.p,{children:"Principe: breng AI naar data, niet andersom. Anti-pattern: on-premise data uploaden naar cloud AI \u2013 risico's op lekken, privacy-schendingen. Best practice: on-premise data + on-premise AI \u2013 controle, soevereiniteit."}),"\n",(0,t.jsx)(n.p,{children:'Geen ongecontroleerde cloud-koppelingen: zelfs "veilige" clouds kunnen geopolitiek wapen worden, onder vreemde wetten vallen, veranderen of data trainen.'}),"\n",(0,t.jsx)(n.p,{children:"Recente voorbeelden: in december 2025 lekte Eindhoven gevoelige residentdata door ambtenaren die bestanden uploaden naar public AI-sites als ChatGPT \u2013 privacy-schending, gemeld aan AP. Dit toont risico's van cloud-AI \u2013 on-premise voorkomt zulke lekken."}),"\n",(0,t.jsx)(n.h2,{id:"ai-als-ondersteunende-tool-samenvatten-genereren-structureren--met-menselijke-controle",children:"AI als Ondersteunende Tool: Samenvatten, Genereren, Structureren \u2013 Met Menselijke Controle"}),"\n",(0,t.jsx)(n.p,{children:"AI mag in overheid ondersteunen, niet leiden. Het kan lange dossiers samenvatten tot kernpunten, conceptbrieven of adviezen genereren voor snelle drafts, en ongestructureerde data zoals emails structureren door naam, BSN of urgentie te extracten. Maar altijd met menselijke controle: ambtenaar checkt output, past aan, beslist \u2013 AI versnelt, mens waarborgt accuraatheid en ethiek."}),"\n",(0,t.jsx)(n.p,{children:"Rode lijn: nooit autonoom \u2013 geen besluiten, overboekingen, wijzigingen. Altijd menselijke controle."}),"\n",(0,t.jsx)(n.h2,{id:"kritische-vraag-blijft-ai-altijd-ondersteunend",children:"Kritische Vraag: Blijft AI Altijd Ondersteunend?"}),"\n",(0,t.jsx)(n.p,{children:"Is AI altijd ondersteunend houden haalbaar, of krijgt het meer autonomie? Ons antwoord: grens rigide houden. Autonomie verliest controle, verantwoordelijkheid \u2013 onacceptabel voor democratie."}),"\n",(0,t.jsx)(n.h2,{id:"conclusie",children:"Conclusie"}),"\n",(0,t.jsx)(n.p,{children:"AI-integratie draait om balans: redenering voor inzicht, veilige data-ophaal, MCP voor context, engines als n8n en Flowable voor logica. AI niet voor afhandeling \u2013 onvoorspelbaar \u2013 maar voor advies, regels verzamelen (via regels.overheid.nl), processen inrichten. Mens beslist altijd."}),"\n",(0,t.jsx)(n.p,{children:"De keuze? Verantwoorde AI bouwen \u2013 passend bij publieke waarden."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Volgende blog:"})," Veilige AI - Handelingskaders en R-bak/P-bak integratie"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Gerelateerd:"})," ",(0,t.jsx)(n.a,{href:"https://modelcontextprotocol.io",children:"MCP Protocol"})," | ",(0,t.jsx)(n.a,{href:"https://regels.overheid.nl",children:"regels.overheid.nl"})]}),"\n",(0,t.jsx)(n.h2,{id:"bronnen",children:"Bronnen"}),"\n",(0,t.jsx)(n.p,{children:"Hieronder een totale, overzichtelijke lijst van alle gebruikte bronnen (alfabetisch gesorteerd op publicatie):"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Anthropic"})," - Model Context Protocol (MCP) documentatie: ",(0,t.jsx)(n.a,{href:"https://docs.anthropic.com/en/api/messages%5B%5E4",children:"https://docs.anthropic.com/en/api/messages[^4"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Common Ground"})," - Veilige AI-integratie in overheidslandschap: ",(0,t.jsx)(n.a,{href:"https://commonground.nl/groups/view/6f1a5b6c-4d0a-4b0a-8b0a-0b0a0b0a0b0a/ai-in-common-ground%5B%5E1",children:"https://commonground.nl/groups/view/6f1a5b6c-4d0a-4b0a-8b0a-0b0a0b0a0b0a/ai-in-common-ground[^1"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"EU AI Act"})," - Offici\xeble tekst over high-risk AI-systemen: ",(0,t.jsx)(n.a,{href:"https://artificialintelligenceact.eu/the-act/%5B%5E3",children:"https://artificialintelligenceact.eu/the-act/[^3"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Flowable"})," - Open source DMN engine (opvolger Camunda): ",(0,t.jsx)(n.a,{href:"https://flowable.com/%5B%5E10",children:"https://flowable.com/[^10"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"iBestuur"})," - Artikelen over AI in overheid: ",(0,t.jsx)(n.a,{href:"https://ibestuur.nl/artikel/ai-in-de-overheid-veilig-integreren%5B%5E2",children:"https://ibestuur.nl/artikel/ai-in-de-overheid-veilig-integreren[^2"}),"][^7][^12]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"n8n"})," - Workflow engine voor business logica: ",(0,t.jsx)(n.a,{href:"https://n8n.io/%5B%5E7",children:"https://n8n.io/[^7"}),"][^8][^9]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"NL Times"})," - Eindhoven data leak via AI sites: ",(0,t.jsx)(n.a,{href:"https://nltimes.nl/2025/12/19/eindhoven-officials-expose-resident-data-public-ai-websites%5B%5E28",children:"https://nltimes.nl/2025/12/19/eindhoven-officials-expose-resident-data-public-ai-websites[^28"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OAuth"})," - Standaard voor token-based access: ",(0,t.jsx)(n.a,{href:"https://oauth.net/%5B%5E19",children:"https://oauth.net/[^19"}),"]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rathenau Instituut"})," - Rapporten over AI-ethiek en bias: diverse publicaties over transparantie.[^5][^6][^8]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"regels.overheid.nl"})," - Machine-leesbare regelgeving: ",(0,t.jsx)(n.a,{href:"https://regels.overheid.nl/%5B%5E14",children:"https://regels.overheid.nl/[^14"}),"][^15]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rijksoverheid"})," - Visie op generatieve AI: ",(0,t.jsx)(n.a,{href:"https://open.overheid.nl/documenten/9aa7b64a-be51-4fc4-8dac-1d4a3e0b02ba/file%5B%5E9",children:"https://open.overheid.nl/documenten/9aa7b64a-be51-4fc4-8dac-1d4a3e0b02ba/file[^9"}),"][^19]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"VNG"})," - Common Ground en AI: ",(0,t.jsx)(n.a,{href:"https://vng.nl/projecten/common-ground-ai%5B%5E13",children:"https://vng.nl/projecten/common-ground-ai[^13"}),"][^14]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Waag"})," - Discussies over open AI in publieke sector: ",(0,t.jsx)(n.a,{href:"https://waag.org/nl/article/open-ai-overheid%5B%5E15",children:"https://waag.org/nl/article/open-ai-overheid[^15"}),"][^16][^23][^24][^26]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Zeebe"})," - Open source workflow engine: ",(0,t.jsx)(n.a,{href:"https://zeebe.io/%5B%5E10",children:"https://zeebe.io/[^10"}),"]"]}),"\n"]})]})}function g(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>l});var a=i(6540);const t={},r=a.createContext(t);function o(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),a.createElement(r.Provider,{value:n},e.children)}},9411(e){e.exports=JSON.parse('{"permalink":"/blog/ai-techniek-integratie-mcp-mistral","source":"@site/blog/platform-ai-en-overheid/2025-01-18-ai-techniek-integratie.md","title":"AI en Techniek - Veilige integratie en het Mistral-vraagstuk","description":"Deze blog is nog in concept-fase en wordt mogelijk nog aangepast voor publicatie.","date":"2025-01-18T00:00:00.000Z","tags":[{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"techniek","permalink":"/blog/tags/techniek"},{"inline":true,"label":"mcp","permalink":"/blog/tags/mcp"},{"inline":true,"label":"mistral","permalink":"/blog/tags/mistral"},{"inline":true,"label":"platform-ai","permalink":"/blog/tags/platform-ai"},{"inline":true,"label":"overheid","permalink":"/blog/tags/overheid"},{"inline":true,"label":"modellen","permalink":"/blog/tags/modellen"}],"readingTime":9.19,"hasTruncateMarker":true,"authors":[{"name":"Ruben van de Linde","title":"Software Developer","url":"https://github.com/rubenvdlinde","email":"your-email@example.com","imageURL":"https://github.com/rubenvdlinde.png","key":"ruben","page":null}],"frontMatter":{"slug":"ai-techniek-integratie-mcp-mistral","title":"AI en Techniek - Veilige integratie en het Mistral-vraagstuk","authors":["ruben"],"tags":["ai","techniek","mcp","mistral","platform-ai","overheid","modellen"]},"unlisted":false,"prevItem":{"title":"Veilige AI - Handelingskaders en de R-bak/P-bak structuur","permalink":"/blog/ai-veilig-handelingskaders-rbak-pbak"},"nextItem":{"title":"AI en Data - Waarom de datalaag alles bepaalt","permalink":"/blog/ai-data-datalaag-basis"}}')}}]);