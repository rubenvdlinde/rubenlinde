"use strict";(globalThis.webpackChunkrubenlinde_website=globalThis.webpackChunkrubenlinde_website||[]).push([[1621],{2954(e){e.exports=JSON.parse('{"permalink":"/blog/ai-veilig-handelingskaders-rbak-pbak","source":"@site/blog/platform-ai-en-overheid/2025-01-19-ai-praktijk-handelingskaders.md","title":"Veilige AI - Handelingskaders en de R-bak/P-bak structuur","description":"Deze blog is nog in concept-fase en wordt mogelijk nog aangepast voor publicatie.","date":"2025-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"beveiliging","permalink":"/blog/tags/beveiliging"},{"inline":true,"label":"handelingskaders","permalink":"/blog/tags/handelingskaders"},{"inline":true,"label":"platform-ai","permalink":"/blog/tags/platform-ai"},{"inline":true,"label":"overheid","permalink":"/blog/tags/overheid"},{"inline":true,"label":"ethiek","permalink":"/blog/tags/ethiek"},{"inline":true,"label":"privacy","permalink":"/blog/tags/privacy"}],"readingTime":5.41,"hasTruncateMarker":true,"authors":[{"name":"Ruben van de Linde","title":"Software Developer","url":"https://github.com/rubenvdlinde","email":"your-email@example.com","imageURL":"https://github.com/rubenvdlinde.png","key":"ruben","page":null}],"frontMatter":{"slug":"ai-veilig-handelingskaders-rbak-pbak","title":"Veilige AI - Handelingskaders en de R-bak/P-bak structuur","authors":["ruben"],"tags":["ai","beveiliging","handelingskaders","platform-ai","overheid","ethiek","privacy"]},"unlisted":false,"prevItem":{"title":"AI Kansen voor Burgers - De Regelgeving Navigator","permalink":"/blog/ai-kansen-burgers-regelgeving-navigator"},"nextItem":{"title":"AI en Techniek - Veilige integratie en het Mistral-vraagstuk","permalink":"/blog/ai-techniek-integratie-mcp-mistral"}}')},8453(e,n,i){i.d(n,{R:()=>s,x:()=>l});var r=i(6540);const a={},t=r.createContext(a);function s(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(t.Provider,{value:n},e.children)}},9040(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>c,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var r=i(2954),a=i(4848),t=i(8453);const s={slug:"ai-veilig-handelingskaders-rbak-pbak",title:"Veilige AI - Handelingskaders en de R-bak/P-bak structuur",authors:["ruben"],tags:["ai","beveiliging","handelingskaders","platform-ai","overheid","ethiek","privacy"]},l="Veilige AI: Handelingskaders en de R-bak/P-bak structuur",o={authorsImageUrls:[void 0]},d=[{value:"De Uitdaging: AI Binnen Strakke Grenzen Houden",id:"de-uitdaging-ai-binnen-strakke-grenzen-houden",level:2},{value:"AI en de R-bak: Restrictief en Met Toestemming",id:"ai-en-de-r-bak-restrictief-en-met-toestemming",level:2},{value:"AI en de P-bak: Ruimte voor Analyses, Met Waarborgen",id:"ai-en-de-p-bak-ruimte-voor-analyses-met-waarborgen",level:2},{value:"Handelingskaders: Wat Mag AI Wel en Niet Doen?",id:"handelingskaders-wat-mag-ai-wel-en-niet-doen",level:2},{value:"Technische Implementatie: Grenzen Afdwingen",id:"technische-implementatie-grenzen-afdwingen",level:2},{value:"Ethische Handelingsbevoegdheid: Mens Centraal",id:"ethische-handelingsbevoegdheid-mens-centraal",level:2},{value:"Kritische Vraag: Vergroten We de Kloof Als We AI Niet Inzetten?",id:"kritische-vraag-vergroten-we-de-kloof-als-we-ai-niet-inzetten",level:2},{value:"Conclusie",id:"conclusie",level:2},{value:"Bronnen",id:"bronnen",level:2}];function g(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.admonition,{title:"Status: Concept",type:"warning",children:(0,a.jsx)(n.p,{children:"Deze blog is nog in concept-fase en wordt mogelijk nog aangepast voor publicatie."})}),"\n",(0,a.jsx)(n.p,{children:'Stel je voor dat je als ambtenaar een AI-tool gebruikt voor een belangrijke beslissing \u2013 een subsidieaanvraag, een vergunning, een handhavingsactie. Het advies komt binnen: "goedkeuren". Maar hoe weet je dat dit veilig is? Heeft de AI alleen de juiste data gezien? Bleef het binnen juridische en ethische grenzen? En wat als het fout gaat \u2013 wie is er dan verantwoordelijk? Veilige AI is geen technische luxe; het is een bestuurlijke en democratische noodzaak. AI kan de overheid effici\xebnter en menselijker maken, maar alleen als we het streng begrenzen met duidelijke handelingskaders.[^1][^2] In Nederland hebben we al een sterke basis met de R-bak/P-bak-structuur \u2013 laten we die gebruiken om AI verantwoord in te zetten.'}),"\n",(0,a.jsx)(n.p,{children:"Dit blog duikt in hoe we AI technisch en ethisch begrenzen, met praktische voorbeelden en een duidelijke scheiding tussen wat AI mag (voorbereiden en adviseren) en wat niet (beslissen). Want de mens blijft altijd aan het roer \u2013 dat is geen compromis, maar een principe.[^3]"}),"\n",(0,a.jsx)(n.h2,{id:"de-uitdaging-ai-binnen-strakke-grenzen-houden",children:"De Uitdaging: AI Binnen Strakke Grenzen Houden"}),"\n",(0,a.jsxs)(n.p,{children:["AI zonder grenzen is gevaarlijk \u2013 het kan biases versterken, privacy schenden of besluiten nemen die niemand begrijpt.[^4] Maar welke grenzen precies? En hoe dwing je die af? In de Nederlandse overheid gebruiken we de ",(0,a.jsx)(n.strong,{children:"R-bak en P-bak"}),"-structuur voor gegevensverwerking: een slimme scheiding die perfect aansluit bij veilige AI.[^5]"]}),"\n",(0,a.jsx)(n.p,{children:"De R-bak (Registratie) bevat authentieke brongegevens \u2013 BSN's uit de BRP, adressen uit de BAG, financi\xeble info. De P-bak (Verwerking) is voor afgeleide analyses en aggregaties. AI moet weten uit welke bak het mag halen, welke privacy-regels gelden, binnen welke kaders het opereert, en altijd verantwoording afleggen.[^6]"}),"\n",(0,a.jsx)(n.p,{children:"Zonder dit risico's: oncontroleerbare toegang, privacy-lekken, juridische problemen.[^7] Met dit: transparantie, controle, vertrouwen."}),"\n",(0,a.jsx)(n.h2,{id:"ai-en-de-r-bak-restrictief-en-met-toestemming",children:"AI en de R-bak: Restrictief en Met Toestemming"}),"\n",(0,a.jsx)(n.p,{children:"De R-bak is heilig \u2013 hier liggen gevoelige brondata zoals BSN-gegevens, medische info of strafrechtelijke feiten.[^8] AI krijgt hier zeer beperkte toegang: alleen noodzakelijke, gepseudonimiseerde data via gecontroleerde API's, gelogd en geauditeerd.[^9]"}),"\n",(0,a.jsx)(n.p,{children:"Praktijkvoorbeeld: een AI helpt bij subsidiechecks. Onveilig: AI duikt rechtstreeks in de BRP en leest volledige historie \u2013 privacy-risico's galore.[^10] Veilig: burger geeft toestemming, applicatie vraagt alleen leeftijd, woonplaats en gezinssamenstelling op. AI analyseert dat, geeft advies. Geen vrije toegang, altijd begrensd.[^11]"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:"flowchart TD\n    A[Burger geeft toestemming] --\x3e B[Applicatie vraagt specifieke data]\n    B --\x3e C[R-bak levert alleen nodige info<br>(leeftijd, woonplaats, gezin)]\n    C --\x3e D[AI analyseert]\n    D --\x3e E[AI geeft advies: wel/niet in aanmerking]\n    E --\x3e F[Ambtenaar controleert en beslist]\n    style C fill:#f9f,stroke:#333,stroke-width:2px\n    style D fill:#bbf,stroke:#333,stroke-width:2px\n"})}),"\n",(0,a.jsx)(n.p,{children:"Dit houdt AI restrictief \u2013 privacy-conform en verantwoord.[^12]"}),"\n",(0,a.jsx)(n.h2,{id:"ai-en-de-p-bak-ruimte-voor-analyses-met-waarborgen",children:"AI en de P-bak: Ruimte voor Analyses, Met Waarborgen"}),"\n",(0,a.jsx)(n.p,{children:"In de P-bak is meer speelruimte: statistieken, trends, geanonimiseerde datasets.[^13] Hier kan AI waarde toevoegen: patronen spotten, inzichten genereren voor beleid."}),"\n",(0,a.jsx)(n.p,{children:"Toegestaan: geaggregeerde analyses, zoals gemiddelde woonlasten per wijk \u2013 geen individuele data, wel beleidsinzichten.[^14] Niet toegestaan: herleidbare profielen, discriminatie of zwarte lijsten zonder grondslag.[^15]"}),"\n",(0,a.jsx)(n.p,{children:'Voorbeeld: AI analyseert woonlasten \u2013 trend "stijgend" in Centrum-wijk. Privacy-conform, nuttig voor beleid.[^16]'}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:"flowchart LR\n    subgraph P-bak [P-bak: Verwerking]\n        A[Geaggregeerde data] --\x3e B[AI analyseert trends]\n        B --\x3e C[Inzichten: gemiddelde kosten, patronen]\n    end\n    subgraph R-bak [R-bak: Registratie]\n        D[Brondata] -- Geen directe toegang --\x3e B\n    end\n    style P-bak fill:#ff9,stroke:#333\n    style R-bak fill:#9f9,stroke:#333\n"})}),"\n",(0,a.jsx)(n.p,{children:"AI verrijkt, maar blijft binnen waarborgen.[^17]"}),"\n",(0,a.jsx)(n.h2,{id:"handelingskaders-wat-mag-ai-wel-en-niet-doen",children:"Handelingskaders: Wat Mag AI Wel en Niet Doen?"}),"\n",(0,a.jsx)(n.p,{children:"Handelingsbevoegdheid van AI? Beperkt. AI mag voorbereiden en adviseren \u2013 nooit beslissen.[^18]"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"AI mag voorbereiden:"})," conceptteksten, samenvattingen, opties presenteren \u2013 altijd ambtenaar-controle.[^19] Voorbeeld: burger vraagt vergunning, AI genereert concept-beoordeling. Ambtenaar checkt, past aan, beslist.[^20]"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"AI mag adviseren:"}),' aanbevelingen, risico\'s signaleren \u2013 duidelijk gemarkeerd als advies.[^21] Voorbeeld: "Op basis van vergelijkbare gevallen optie B" \u2013 ambtenaar beoordeelt zelf.']}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"AI mag NOOIT beslissen:"})," geen zelfstandige besluiten, rechten toekennen/ontzeggen, geld overmaken.[^22] Waarom? Juridisch: besluit herleidbaar tot ambtenaar (Awb). Democratisch: mens verantwoordelijk. Ethisch: AI geen moreel kompas. Praktisch: AI kan fouten maken.[^23]"]}),"\n",(0,a.jsx)(n.h2,{id:"technische-implementatie-grenzen-afdwingen",children:"Technische Implementatie: Grenzen Afdwingen"}),"\n",(0,a.jsx)(n.p,{children:"Technisch afdwingen met RBAC: AI role leest beperkt, schrijft drafts/logs \u2013 nooit offici\xeble besluiten.[^24]"}),"\n",(0,a.jsx)(n.p,{children:"API-gateway: validatie, permission check, privacy filter, logging.[^25]"}),"\n",(0,a.jsx)(n.p,{children:"Audit trail: elke actie vastgelegd \u2013 input, output, reasoning, menselijke beslissing.[^26]"}),"\n",(0,a.jsx)(n.p,{children:'On-premise: AI "in de kelder" \u2013 data verlaat nooit infrastructuur, compliance met AVG.[^27]'}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    subgraph Kasteel [Gemeente Kasteel - On-Premise]\n        R[R-bak: Brondata] <--\x3e|Beperkte API| AI[AI Engine]\n        P[P-bak: Analyses] <--\x3e AI\n        App[Applicaties] <--\x3e AI\n        Logs[Audit Logs] <-- AI\n    end\n    External[Externe Clouds] -- Geen toegang --\x3e Kasteel\n    style Kasteel fill:#ddf,stroke:#333,stroke-width:4px\n"})}),"\n",(0,a.jsx)(n.p,{children:"Veilig binnen muren.[^28]"}),"\n",(0,a.jsx)(n.h2,{id:"ethische-handelingsbevoegdheid-mens-centraal",children:"Ethische Handelingsbevoegdheid: Mens Centraal"}),"\n",(0,a.jsx)(n.p,{children:"Techniek alleen volstaat niet \u2013 ethiek is key.[^29] Verantwoord: AI versnelt werk, voorkomt fouten, maakt toegankelijker \u2013 mens eindverantwoordelijk.[^30]"}),"\n",(0,a.jsx)(n.p,{children:"Problematisch: AI vervangt oordeel, discrimineert, machteloosheid cre\xebert.[^31]"}),"\n",(0,a.jsx)(n.p,{children:"Voorbeeld SyRI: verboden door black box, discriminatie-risico, disproportioneel.[^32] Les: transparant, uitlegbaar, proportioneel.[^33]"}),"\n",(0,a.jsx)(n.p,{children:"Kaders: transparantie (burger weet AI-gebruik), proportionaliteit, menselijke controle, non-discriminatie (bias-testing).[^34]"}),"\n",(0,a.jsx)(n.h2,{id:"kritische-vraag-vergroten-we-de-kloof-als-we-ai-niet-inzetten",children:"Kritische Vraag: Vergroten We de Kloof Als We AI Niet Inzetten?"}),"\n",(0,a.jsx)(n.p,{children:"Als we AI niet inzetten om burgers door regeldoolhoven te helpen, profiteren alleen digitaal vaardigen \u2013 vergroten we de kloof niet?[^35]"}),"\n",(0,a.jsx)(n.p,{children:"Antwoord: ja, daarom w\xe9l inzetten \u2013 verantwoord, binnen kaders, voor iedereen toegankelijk.[^36]"}),"\n",(0,a.jsx)(n.h2,{id:"conclusie",children:"Conclusie"}),"\n",(0,a.jsx)(n.p,{children:"Goed ingerichte AI vergroot bestaanszekerheid, niet bureaucratie. Technische waarborgen (R-bak/P-bak, API's, trails), juridische kaders (bevoegdheid, transparantie), ethische grenzen (mens beslist, non-discriminatie), on-premise (kasteel)."}),"\n",(0,a.jsx)(n.p,{children:"AI voorbereidt en adviseert. Mens beslist."}),"\n",(0,a.jsx)(n.p,{children:"Met waarborgen maken we overheid toegankelijker, effectiever, menselijker \u2013 zonder concessies aan veiligheid, privacy, democratie.[^37]"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Vorige blog:"})," AI en Techniek - Veilige integratie met MCP"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Gerelateerd:"})," ",(0,a.jsx)(n.a,{href:"https://commonground.nl",children:"Common Ground"})]}),"\n",(0,a.jsx)(n.h2,{id:"bronnen",children:"Bronnen"}),"\n",(0,a.jsx)(n.p,{children:"Hieronder een totale, overzichtelijke lijst van alle gebruikte bronnen (alfabetisch gesorteerd op publicatie):"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Common Ground"})," - R-bak/P-bak structuur en principes: ",(0,a.jsx)(n.a,{href:"https://commonground.nl/%5B%5E5",children:"https://commonground.nl/[^5"}),"][^6][^7][^8]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"EU AI Act"})," - High-risk AI en transparantie: ",(0,a.jsx)(n.a,{href:"https://artificialintelligenceact.eu/%5B%5E3",children:"https://artificialintelligenceact.eu/[^3"}),"][^34]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"iBestuur"})," - Artikelen over AI-kaders in overheid: ",(0,a.jsx)(n.a,{href:"https://ibestuur.nl/%5B%5E1",children:"https://ibestuur.nl/[^1"}),"][^2][^4][^9][^11][^12][^15][^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^26][^27][^28][^29][^30][^31][^32][^33][^35][^36][^37]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Rathenau Instituut"})," - Ethische AI en SyRI-analyse: diverse rapporten.[^31][^32]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Rijksoverheid"})," - Visie generatieve AI en handelingskaders: ",(0,a.jsx)(n.a,{href:"https://open.overheid.nl/%5B%5E10",children:"https://open.overheid.nl/[^10"}),"][^14]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"VNG"})," - AI in gemeentelijke praktijk: ",(0,a.jsx)(n.a,{href:"https://vng.nl/%5B%5E13",children:"https://vng.nl/[^13"}),"]"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Waag"})," - Open AI en ethiek: ",(0,a.jsx)(n.a,{href:"https://waag.org/%5B%5E30",children:"https://waag.org/[^30"}),"]"]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(g,{...e})}):g(e)}}}]);