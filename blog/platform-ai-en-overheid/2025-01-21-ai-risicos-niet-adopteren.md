---
slug: ai-risicos-niet-adopteren-achterblijven
title: Risico's van Niet-Adopteren - Als de overheid AI negeert
authors: [ruben]
tags: [ai, strategie, overheid]
---

# Risico's van Niet-Adopteren: Als de overheid AI negeert

:::warning Status: Concept
Deze blog is nog in concept-fase en wordt mogelijk nog aangepast voor publicatie.
:::

We praten veel over de risico's van AI – bias, privacy, banenverlies, black boxes. Terecht, want die gevaren zijn reëel en moeten we serieus nemen. Maar er is een ander risico dat vaak onderbelicht blijft, en dat misschien wel groter is: het risico van **niet adopteren**. Terwijl we eindeloos discussiëren, pilots uitstellen en wachten op perfectie, gaat de wereld om ons heen vol gas vooruit. Bedrijven, burgers en andere landen omarmen AI – en de overheid blijft achter. Dat is geen neutrale positie; dat is een keuze met verstrekkende gevolgen.[^1][^2]

Stel je voor: over een paar jaar hebben burgers persoonlijke AI-assistenten die alles regelen – van belastingen tot zorgaanvragen. Ze verwachten dat de overheid net zo snel, slim en persoonlijk is. Maar als we nu niet investeren, wordt de kloof onoverbrugbaar. Achterblijven is niet stilstand; het is achteruitgang. Laten we kijken naar de risico's van niet meedoen – want die zijn minstens zo groot als de risico's van wel doen.[^3]

<!--truncate-->

## Risico 1: Achterblijven in Dienstverlening – De Kloof Wordt Onoverbrugbaar

Andere landen en sectoren investeren volop in AI voor publieke dienstverlening. Estland heeft een bijna volledig gedigitaliseerde overheid met AI-ondersteuning; Singapore gebruikt AI voor vergunningen en belasting; Denemarken automatiseert aangiftes met slimme checks.[^4] Ondertussen worstelen Nederlandse gemeenten nog met papieren processen, versnipperde systemen en overbelaste ambtenaren – lange wachttijden, frustratie.[^5]

Burgers zijn gewend aan Netflix die perfect aanbeveelt, Spotify die playlists maakt, ChatGPT die complexe vragen beantwoordt. Ze verwachten van de overheid: snelle, persoonlijke service, 24/7 beschikbaar, begrijpelijke antwoorden.[^6] Als we dat niet bieden, groeit vervreemding. De private sector wordt efficiënter – processen in minuten, foutloos. De overheid blijft weken doen over eenvoudige zaken – traag, duur, ouderwets.[^7]

Resultaat? Vertrouwen daalt, burgers haken af, en de kloof tussen "digitaal vaardig" en "achterblijver" wordt groter.[^8] Niet-adopteren vergroot ongelijkheid in plaats van verkleint.[^9]

## Risico 2: Verlies van Controle – Anderen Bepalen Onze Standaarden

Als Nederland niet meedoet aan AI-ontwikkeling, bepalen anderen de regels. Amerikaanse big tech dicteert standaarden, Chinese systemen worden norm, EU-beleid zonder Nederlandse inbreng.[^10] We worden tech-kolonie – afhankelijk van buitenlandse vendors.[^11]

Zonder eigen capaciteit: problemen oplossen door inhuren externe partij – geen interne kennis, vendor lock-in, prijsopdrijving – vicieuze cirkel.[^12] Soevereiniteit vereist eigen technologie, kennis, standaarden.[^13] Niet-adopteren betekent verlies daarvan – geopolitiek risico, zoals Cloud Act.[^14]

## Risico 3: Innovatie Stagnatie – Talent en Kansen Vertrekken

Slimme koppen gaan waar actie is: AI-specialisten naar bedrijven, onderzoekers buitenland, innovators Silicon Valley.[^15] Overheid blijft met vergrijzende workforce, verouderde kennis – geen aansluiting ontwikkelingen.[^16]

Maatschappelijke problemen blijven: AI kan vroegtijdig schulden signaleren, zorg efficiënter maken, onderwijs personaliseren – zonder AI missen we dat.[^17] Voorbeeld: ethische vroegsignalering schulden helpt duizenden – maar gebeurt niet zonder AI.[^18]

## Risico 4: Ethische Achterstand – Geen Stem in het Debat

Niet meedoen betekent geen stem in ethiek-debat: welke waarden inbouwen, rechtvaardigheid borgen, grenzen stellen.[^19] Anderen bepalen wat ethisch is – onze waarden niet vertegenwoordigd.[^20] Achteraf bijsturen te laat.[^21]

Maatschappelijk: zonder publieke AI alleen commerciële – voor wie betaalt, digitaal vaardig – ongelijkheid groeit.[^22] Met publieke AI: toegankelijk iedereen, rekening diversiteit – kloof verkleint.[^23]

## Risico 5: De AI-Assistent Paradox – Burgers Voorop, Overheid Achterop

Burgers krijgen AI-assistenten: ChatGPT, Claude, Gemini – helpen dagelijks, inclusief overheid.[^24]

Scenario: burger met AI genereert perfecte aanvragen, bezwaren in minuten – juridisch waterdicht, massa.[^25]

Overheid zonder AI: handmatig behandelen, overspoeld, wachttijden exploderen – systeem crasht.[^26]

Asymmetrie: burgers efficiënt, overheid niet – frustratie, ongelijkheid (wie premium AI betaalt profiteert).[^27]

## Risico 6: Economische Achterstand – Concurrentie Verschuift

Bedrijven met AI: productiever, innovatiever, goedkoper.[^28] Overheid zonder: bureaucratie duur, innovatie gehinderd, talent weg – economie groeit minder.[^29]

Internationaal: AI-competente overheden aantrekkelijk bedrijven, hubs innovatie.[^30] Nederland zonder: minder aantrekkelijk, brain drain.[^31]

## Scenario's 2030: Twee Toekomsten

**2030 zonder AI-overheid:** Burgers gefrustreerd instant antwoorden verwachten, ambtenaren overspoeld AI-aanvragen, vertrouwen daalt, afhankelijk big tech, kloof groeit.[^32]

**2030 met AI-overheid:** Gratis assistent iedereen, snelle service, ambtenaren focus complex, vertrouwen groeit, soeverein.[^33]

## Kritische Vraag: Kunnen We Ons Geen AI Verloren?

Durven we achterblijven terwijl burgers AI verwachten? Riskeren we aansluiting samenleving verliezen?[^34]

Antwoord: nee – niet-adopteren onbetaalbaar.[^35]

## Conclusie: Niet-Doen is de Slechtste Keuze

Geen neutrale positie – niet kiezen slechtste.[^36]

Opties: afwachten (achterstand), inkopen (lock-in), zelf bouwen Common Ground (soeverein).[^37]

Keuze duidelijk: zelf bouwen.

Actiepunten: investeren competentie, experimenteren pilots, samenwerken Common Ground, opleiden, bouwen capaciteit.[^38]

Wereld wacht niet – kloof groeit dagelijks.

Vraag niet of AI veroorloven, maar geen AI.[^39]

Antwoord: nee.

**Einde blog-serie!**

**Alle blogs:**

**AI & Overheid:**

1. [AI Bubbels en Wereldbeeld](/blog/ai-bubbels-wereldbeeld)
2. [AI en Open Source](/blog/ai-open-source-common-ground)
3. [AI en Data](/blog/ai-data-datalaag-basis)
4. [AI en Techniek](/blog/ai-techniek-integratie-mcp-mistral)
5. [Veilige AI](/blog/ai-veilig-handelingskaders-rbak-pbak)
6. [Kansen voor Burgers](/blog/ai-kansen-burgers-regelgeving-navigator)
7. [Risico's Niet-Adopteren](/blog/ai-risicos-niet-adopteren-achterblijven) ← **Je bent hier**

**Open Source & Europa:** 8. [Einde Pax Americana](/blog/einde-pax-americana-digitale-soevereiniteit) 9. [Eurostack & Common Ground](/blog/eurostack-common-ground-europese-samenwerking) 10. [Open Source voor MKB](/blog/open-source-mkb-public-functionality)

**Gerelateerd:** [Common Ground](https://commonground.nl)

## Bronnen

- [^1]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^2]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^3]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^4]: **VNG** - [Voorbeelden internationale AI-overheid](https://vng.nl/)
- [^5]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^6]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^7]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^8]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^9]: **Waag** - [Discussies over AI en kloof](https://waag.org/)
- [^10]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^11]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^12]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^13]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^14]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^15]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^16]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^17]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^18]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^19]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^20]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^21]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^22]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^23]: **Rathenau Instituut** - Rapporten AI-adoptie en maatschappelijke risico's
- [^24]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^25]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^26]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^27]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^28]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^29]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^30]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^31]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^32]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^33]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^34]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^35]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^36]: **iBestuur** - [Risico's achterblijven AI overheid](https://ibestuur.nl/)
- [^37]: **Common Ground** - [Principes en risico's niet-adopteren](https://commonground.nl/)
- [^38]: **Common Ground** - [Principes en risico's niet-adopteren](https://commonground.nl/)
- [^39]: **Rijksoverheid** - [Visie AI en achterstand risico's](https://open.overheid.nl/)
