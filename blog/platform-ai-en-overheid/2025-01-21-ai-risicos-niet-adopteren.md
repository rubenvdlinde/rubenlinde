---
slug: ai-risicos-niet-adopteren-achterblijven
title: Risico's van Niet-Adopteren - Als de overheid AI negeert
authors: [ruben]
tags: [ai, overheid, platform-ai-en-overheid]
---

# Risico's van Niet-Adopteren: Als de overheid AI negeert

:::info Platform AI en Overheid
Deze blog is geschreven in het kader van [Platform AI en Overheid](https://www.platformaienoverheid.nl/), een initiatief gericht op verantwoorde AI-adoptie binnen de publieke sector.
:::

We praten veel over de risico's van AI – bias, privacy, banenverlies, black boxes. Terecht, want die gevaren zijn reëel en moeten we serieus nemen.[^2][^8] Maar er is een ander risico dat vaak onderbelicht blijft, en dat misschien wel groter is: het risico van **niet adopteren**. Terwijl we eindeloos discussiëren, pilots uitstellen en wachten op perfectie, gaat de wereld om ons heen vol gas vooruit. Bedrijven, burgers en andere landen omarmen AI – en de overheid blijft achter.[^1][^2] Dat is geen neutrale positie; dat is een keuze met verstrekkende gevolgen.[^7]

Stel je voor: over een paar jaar hebben burgers persoonlijke AI-assistenten die alles regelen – van belastingen tot zorgaanvragen. Ze verwachten dat de overheid net zo snel, slim en persoonlijk is. Maar als we nu niet investeren, wordt de kloof onoverbrugbaar.[^1][^5] Achterblijven is niet stilstand; het is achteruitgang. Laten we kijken naar de risico's van niet meedoen – want die zijn minstens zo groot als de risico's van wel doen.[^2]

<!--truncate-->

## Risico 1: Achterblijven in Dienstverlening – De Kloof Wordt Onoverbrugbaar

Andere landen en sectoren investeren volop in AI voor publieke dienstverlening. Estland heeft een bijna volledig gedigitaliseerde overheid met AI-ondersteuning; Singapore gebruikt AI voor vergunningen en belasting; Denemarken automatiseert aangiftes met slimme checks.[^4] Ondertussen worstelen Nederlandse gemeenten nog met papieren processen, versnipperde systemen en overbelaste ambtenaren – lange wachttijden, frustratie.[^3][^5]

Burgers zijn gewend aan Netflix die perfect aanbeveelt, Spotify die playlists maakt, ChatGPT die complexe vragen beantwoordt. Ze verwachten van de overheid: snelle, persoonlijke service, 24/7 beschikbaar, begrijpelijke antwoorden.[^1] Als we dat niet bieden, groeit vervreemding. De private sector wordt efficiënter – processen in minuten, foutloos. De overheid blijft weken doen over eenvoudige zaken – traag, duur, ouderwets.[^2][^7]

Resultaat? Vertrouwen daalt, burgers haken af, en de kloof tussen "digitaal vaardig" en "achterblijver" wordt groter.[^5] Niet-adopteren vergroot ongelijkheid in plaats van verkleint.[^5][^7]

## Risico 2: Verlies van Controle – Anderen Bepalen Onze Standaarden

Als Nederland niet meedoet aan AI-ontwikkeling, bepalen anderen de regels. Amerikaanse big tech dicteert standaarden, Chinese systemen worden norm, EU-beleid zonder Nederlandse inbreng.[^2][^8] We worden tech-kolonie – afhankelijk van buitenlandse vendors.[^6][^7]

Zonder eigen capaciteit: problemen oplossen door inhuren externe partij – geen interne kennis, vendor lock-in, prijsopdrijving – vicieuze cirkel.[^3] Soevereiniteit vereist eigen technologie, kennis, standaarden.[^6] Niet-adopteren betekent verlies daarvan – geopolitiek risico, zoals Cloud Act.[^2][^7]

## Risico 3: Innovatie Stagnatie – Talent en Kansen Vertrekken

Slimme koppen gaan waar actie is: AI-specialisten naar bedrijven, onderzoekers buitenland, innovators Silicon Valley.[^1][^2] Overheid blijft met vergrijzende workforce, verouderde kennis – geen aansluiting ontwikkelingen.[^3][^7]

Maatschappelijke problemen blijven: AI kan vroegtijdig schulden signaleren, zorg efficiënter maken, onderwijs personaliseren – zonder AI missen we dat.[^1][^2] Voorbeeld: ethische vroegsignalering schulden helpt duizenden – maar gebeurt niet zonder AI.[^3]

## Risico 4: Ethische Achterstand – Geen Stem in het Debat

Niet meedoen betekent geen stem in ethiek-debat: welke waarden inbouwen, rechtvaardigheid borgen, grenzen stellen.[^2][^8] Anderen bepalen wat ethisch is – onze waarden niet vertegenwoordigd.[^7] Achteraf bijsturen te laat.[^8]

Maatschappelijk: zonder publieke AI alleen commerciële – voor wie betaalt, digitaal vaardig – ongelijkheid groeit.[^5][^7] Met publieke AI: toegankelijk iedereen, rekening diversiteit – kloof verkleint.[^2][^5]

## Risico 5: De AI-Assistent Paradox – Burgers Voorop, Overheid Achterop

Burgers krijgen AI-assistenten: ChatGPT, Claude, Gemini – helpen dagelijks, inclusief overheid.[^1]

Scenario: burger met AI genereert perfecte aanvragen, bezwaren in minuten – juridisch waterdicht, massa.[^1][^7]

Overheid zonder AI: handmatig behandelen, overspoeld, wachttijden exploderen – systeem crasht.[^3][^7]

Asymmetrie: burgers efficiënt, overheid niet – frustratie, ongelijkheid (wie premium AI betaalt profiteert).[^5][^7]

## Risico 6: Economische Achterstand – Concurrentie Verschuift

Bedrijven met AI: productiever, innovatiever, goedkoper.[^1][^2] Overheid zonder: bureaucratie duur, innovatie gehinderd, talent weg – economie groeit minder.[^3][^7]

Internationaal: AI-competente overheden aantrekkelijk bedrijven, hubs innovatie.[^4] Nederland zonder: minder aantrekkelijk, brain drain.[^2][^7]

## Scenario's 2030: Twee Toekomsten

**2030 zonder AI-overheid:** Burgers gefrustreerd instant antwoorden verwachten, ambtenaren overspoeld AI-aanvragen, vertrouwen daalt, afhankelijk big tech, kloof groeit.[^5][^7]

**2030 met AI-overheid:** Gratis assistent iedereen, snelle service, ambtenaren focus complex, vertrouwen groeit, soeverein.[^1][^6]

## Kritische Vraag: Kunnen We Ons Geen AI Verloren?

Durven we achterblijven terwijl burgers AI verwachten? Riskeren we aansluiting samenleving verliezen?[^1][^2]

Antwoord: nee – niet-adopteren onbetaalbaar.[^2][^7]

## Conclusie: Niet-Doen is de Slechtste Keuze

Geen neutrale positie – niet kiezen slechtste.[^2][^7]

Opties: afwachten (achterstand), inkopen (lock-in), zelf bouwen Common Ground (soeverein).[^6]

Keuze duidelijk: zelf bouwen.[^6]

Actiepunten: investeren competentie, experimenteren pilots, samenwerken Common Ground, opleiden, bouwen capaciteit.[^1][^3][^6]

Wereld wacht niet – kloof groeit dagelijks.[^2]

Vraag niet of AI veroorloven, maar geen AI.[^1][^7]

Antwoord: nee.[^2]

[^1]: **Rijksoverheid** - [Kabinet presenteert visie op generatieve AI](https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai)

[^2]: **Rathenau Instituut** - [Zo brengen we AI in de praktijk vanuit Europese waarden](https://www.rathenau.nl/sites/default/files/inline-files/Zo%20brengen%20we%20AI%20in%20de%20praktijk%20vanuit%20Europese%20waarden%20-%20Roos%20de%20Jong%2C%20Linda%20Kool%20en%20Rinie%20van%20Est.pdf)

[^3]: **VNG** - [AI Governancekader voor gemeenten](https://aigovernance.vng.nl/)

[^4]: **e-Estonia** - [Digital society and AI services](https://e-estonia.com/)

[^5]: **SCP** - [Digitale ongelijkheid in Nederland](https://www.scp.nl/publicaties/publicaties/2021/10/07/digitale-ongelijkheid-in-nederland)

[^6]: **Common Ground** - [Architectuur en principes](https://commonground.nl/)

[^7]: **Rathenau Instituut** - [Mens en machine in besluitvorming](https://www.rathenau.nl/nl/digitale-samenleving/mens-en-machine-besluitvorming)

[^8]: **EU AI Act** - [High-risk AI en transparantie](https://artificialintelligenceact.eu/)
